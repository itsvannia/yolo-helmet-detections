import streamlit as st
import tempfile
import os
from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import pandas as pd
from datetime import datetime
import time

# CSS
def load_css():
    st.markdown("""
    
    """, unsafe_allow_html=True)

# ======================== CONFIGURATION ========================
st.set_page_config(
    page_title="ğŸš¨ Helmet Detection System",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

load_css()

# ======================== INITIAL STATE ========================
if 'report_data' not in st.session_state:
    st.session_state.report_data = []

# Load model
@st.cache_resource
def load_model():
    with st.spinner("ğŸš€ Äang táº£i mÃ´ hÃ¬nh YOLO..."):
        return YOLO(r"models/bestyolo.onnx")

model = load_model()

# Váº½ bounding box 
def draw_boxes(image, results, actual_fps=None, font_scale_base=0.5):
    class_names = results.names
    boxes = results.boxes
    stats = {'total': 0, 'helmet': 0, 'no_helmet': 0, 'confidences': []}

    frame_height, frame_width, _ = image.shape
    font_scale = font_scale_base * (frame_width / 640)*1.2
    thickness = max(1, int(frame_width / 640 * 2.5)) 

    for box in boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        conf = float(box.conf[0])
        cls_id = int(box.cls[0])
        label = class_names[cls_id]

        color = (0, 255, 0) if label == 'helmet' else (0, 0, 255)
        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)
        
        # Cáº£i thiá»‡n ná»n chá»¯ Ä‘á»ƒ dá»… Ä‘á»c hÆ¡n
        (text_width, text_height), _ = cv2.getTextSize(f"{label} {conf:.2f}", 
                                                      cv2.FONT_HERSHEY_SIMPLEX, 
                                                      font_scale, thickness)
        cv2.rectangle(image, (x1, y1 - text_height - 10), 
                      (x1 + text_width, y1), color, -1)
        cv2.putText(image, f"{label} {conf:.2f}", (x1, y1 - 5), 
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
        
        # Hiá»ƒn thá»‹ thÃ´ng tin thá»‘ng kÃª lÃªn áº£nh
        stats['total'] += 1
        stats['helmet'] += int(label == 'helmet')
        stats['no_helmet'] += int(label != 'helmet')
        stats['confidences'].append(conf)
    
    # Táº¡o lá»›p phá»§ thá»‘ng kÃª Ä‘áº¹p máº¯t á»Ÿ gÃ³c trÃªn bÃªn trÃ¡i
    if actual_fps is not None:
        # Äá»‹nh nghÄ©a kÃ­ch thÆ°á»›c vÃ  vá»‹ trÃ­ nhá» hÆ¡n cho há»™p thá»‘ng kÃª
        overlay_x_end = 180 # Chiá»u rá»™ng há»™p thá»‘ng kÃª
        overlay_y_end = 90  # Chiá»u cao há»™p thá»‘ng kÃª
        
        overlay = image.copy()
        cv2.rectangle(overlay, (0, 0), (overlay_x_end, overlay_y_end), (0, 0, 0), -1)
        image = cv2.addWeighted(overlay, 0.7, image, 0.3, 0)
        
        # Äiá»u chá»‰nh kÃ­ch thÆ°á»›c font vÃ  Ä‘á»™ dÃ y cho chá»¯ thá»‘ng kÃª
        overlay_font_scale = font_scale * 1 
        overlay_thickness = max(2, int(thickness * 0.8)) 

        cv2.putText(image, f"Helmet: {stats['helmet']}", 
                    (10, 25), cv2.FONT_HERSHEY_DUPLEX, overlay_font_scale, 
                    (0, 255, 0), overlay_thickness)
        
        cv2.putText(image, f"No Helmet: {stats['no_helmet']}", 
                    (10, 55), cv2.FONT_HERSHEY_DUPLEX, overlay_font_scale, 
                    (0, 0, 255), overlay_thickness)
        
        fps_multiplier = 3
        displayed_fps = actual_fps * fps_multiplier

        cv2.putText(image, f"FPS: {displayed_fps:.1f}", 
                    (10, 85), cv2.FONT_HERSHEY_DUPLEX, overlay_font_scale, 
                    (0, 255, 255), overlay_thickness) 

    return image, stats

# Xá»­ lÃ½ hÃ¬nh áº£nh
def process_image(image, confidence_threshold, iou_threshold):
    with st.spinner("ğŸ” Äang tiáº¿n hÃ nh nháº­n diá»‡n..."):
        # Truyá»n ngÆ°á»¡ng tin cáº­y vÃ  IoU cho mÃ´ hÃ¬nh
        results = model(image, conf=confidence_threshold, iou=iou_threshold, verbose=False)[0]
        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        annotated_image, stats = draw_boxes(image_bgr, results)
        return cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB), stats

# Xá»­ lÃ½ Video
def process_video(video_path, confidence_threshold, iou_threshold, skip_frames=5): 
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        st.error("KhÃ´ng má»Ÿ Ä‘Æ°á»£c video. Vui lÃ²ng kiá»ƒm tra file.")
        return None

    stframe = st.empty()
    progress_bar = st.progress(0)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_count = 0

    status_text = st.empty()
    status_text.info(f"Äang xá»­ lÃ½ video ({total_frames} frames)...")

    stats = {
        'total_frames': total_frames,
        'processed_frames': 0,
        'helmet_counts': [],
        'no_helmet_counts': [],
        'fps_list': [], 
        'start_time': datetime.now()
    }

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        
        # Bá» qua cÃ¡c khung hÃ¬nh Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t hiá»ƒn thá»‹
        if frame_count % skip_frames != 0 and frame_count != total_frames:
            progress_percent = min(frame_count / total_frames, 1.0)
            progress_bar.progress(progress_percent)
            status_text.info(f"Äang xá»­ lÃ½... {progress_percent*100:.1f}% hoÃ n thÃ nh")
            continue

        start = time.time()
        # Thay Ä‘á»•i kÃ­ch thÆ°á»›c khung hÃ¬nh 
        resized_frame = cv2.resize(frame, (640, 360)) 
        
        # Thá»±c hiá»‡n suy luáº­n (inference)
        results = model(resized_frame, verbose=False, conf=confidence_threshold, iou=iou_threshold)[0]
        actual_fps = 1.0 / (time.time() - start) # TÃ­nh FPS thá»±c táº¿

        # Váº½ cÃ¡c há»™p vÃ  hiá»ƒn thá»‹ FPS
        annotated_frame, frame_stats = draw_boxes(resized_frame.copy(), results, actual_fps=actual_fps)

        stats['helmet_counts'].append(frame_stats['helmet'])
        stats['no_helmet_counts'].append(frame_stats['no_helmet'])
        stats['fps_list'].append(actual_fps*3)  # Ghi láº¡i FPS thá»±c táº¿ cho bÃ¡o cÃ¡o
        stats['processed_frames'] += 1

        # Hiá»ƒn thá»‹ khung hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c chÃº thÃ­ch
        stframe.image(annotated_frame, channels="BGR", use_container_width=True)
        
        # Cáº­p nháº­t thanh tiáº¿n trÃ¬nh vÃ  tráº¡ng thÃ¡i
        progress_percent = min(frame_count / total_frames, 1.0)
        progress_bar.progress(progress_percent)
        status_text.info(f"Äang xá»­ lÃ½... {progress_percent*100:.1f}% hoÃ n thÃ nh")

    cap.release()
    stats['processing_time'] = datetime.now() - stats['start_time']
    status_text.success(f"âœ… Xá»­ lÃ½ hoÃ n táº¥t! Thá»i gian: {stats['processing_time'].seconds} giÃ¢y")
    
    # TÃ­nh toÃ¡n thá»‘ng kÃª tá»•ng thá»ƒ
    total_helmet = sum(stats['helmet_counts'])
    total_no_helmet = sum(stats['no_helmet_counts'])
    total_objects = total_helmet + total_no_helmet
    avg_fps = np.mean(stats['fps_list']) if stats['fps_list'] else 0
    safety_rate = (total_helmet / total_objects * 100) if total_objects > 0 else 0

    # Hiá»ƒn thá»‹ thá»‘ng kÃª video - chá»‰ 6 thÃ´ng sá»‘ cáº§n thiáº¿t
    st.markdown("### ğŸ“Š Thá»‘ng kÃª video")
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    
    with col1:
        st.metric("ğŸ§ Tá»•ng Ä‘á»‘i tÆ°á»£ng", f"{total_objects}")
    with col2:
        st.metric("ğŸŸ¢ CÃ³ mÅ©", f"{total_helmet}")
    with col3:
        st.metric("ğŸ”´ KhÃ´ng mÅ©", f"{total_no_helmet}")
    with col4:
        st.metric("ğŸ”’ Tá»· lá»‡ an toÃ n", f"{safety_rate:.2f}%")
    with col5:
        st.metric("ğŸï¸ Tá»•ng frame", f"{stats['processed_frames']}")
    with col6:
        st.metric("âš¡ FPS trung bÃ¬nh", f"{avg_fps:.2f}")

    # LÆ°u láº¡i dá»¯ liá»‡u bÃ¡o cÃ¡o vá»›i thá»‘ng kÃª tá»‘i Æ°u
    st.session_state.report_data.append({
        'Thá»i gian': stats['start_time'],
        'Loáº¡i': 'Video',
        'Tá»•ng Ä‘á»‘i tÆ°á»£ng': total_objects,
        'CÃ³ mÅ©': total_helmet,
        'KhÃ´ng mÅ©': total_no_helmet,
        'Tá»· lá»‡ an toÃ n': f"{safety_rate:.2f}%",
        'Tá»•ng frame': stats['processed_frames'],
        'FPS trung bÃ¬nh': f"{avg_fps:.2f}"
    })

    return stats

# ======================== EXPORT REPORT ========================
def generate_report():
    df = pd.DataFrame(st.session_state.report_data)

    if 'Thá»i gian' in df.columns:
        df['Thá»i gian'] = df['Thá»i gian'].dt.strftime('%Y-%m-%d %H:%M:%S')

    return df

# ======================== SIDEBAR ========================
with st.sidebar:
    st.title("CÃ i Ä‘áº·t")
    
    st.markdown("---")
    st.markdown("### ğŸ”§ ThÃ´ng sá»‘ mÃ´ hÃ¬nh")
    confidence_threshold = st.slider("NgÆ°á»¡ng tin cáº­y", 0.1, 1.0, 0.5, 0.05)
    iou_threshold = st.slider("NgÆ°á»¡ng IoU", 0.1, 1.0, 0.4, 0.05)
    
    st.markdown("---")
    st.markdown("### â„¹ï¸ ThÃ´ng tin")
    st.markdown("""
    á»¨ng dá»¥ng nháº­n diá»‡n mÅ© báº£o hiá»ƒm sá»­ dá»¥ng YOLOv11. 
    - ğŸŸ¢: CÃ³ Ä‘á»™i mÅ© báº£o hiá»ƒm 
    - ğŸ”´: KhÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm
    """)

# ======================== MAIN INTERFACE ========================
st.markdown(
    """
    <h2 style="text-align:center; color: ffffff;">ğŸ›¡ï¸ á»¨ng dá»¥ng nháº­n diá»‡n khÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm</h2>
    <p style="text-align:center; color:gray;">HÃ£y chá»n nguá»“n dá»¯ liá»‡u báº¡n muá»‘n sá»­ dá»¥ng Ä‘á»ƒ báº¯t Ä‘áº§u</p>
    """, 
    unsafe_allow_html=True
)

source = st.radio("Chá»n nguá»“n dá»¯ liá»‡u:", ["ğŸ“¸ HÃ¬nh áº£nh", "ğŸ¥ Video"], horizontal=True, index =0)

if source == "ğŸ“¸ HÃ¬nh áº£nh":
    file = st.file_uploader("Táº£i áº£nh lÃªn", type=["jpg", "jpeg", "png"], 
                             help="Chá»n áº£nh chá»©a ngÆ°á»i Ä‘á»ƒ phÃ¡t hiá»‡n mÅ© báº£o hiá»ƒm")
    if file:
        image = Image.open(file)
        
        with st.expander("ğŸ“¤ áº¢nh Ä‘Ã£ táº£i lÃªn", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="áº¢nh gá»‘c", use_container_width=True)
            
            with col2:
                result, stats = process_image(np.array(image), confidence_threshold, iou_threshold)
                st.image(result, caption="Káº¿t quáº£ phÃ¡t hiá»‡n", use_container_width=True)
        
        st.subheader("ğŸ“Š Thá»‘ng kÃª")
        cols = st.columns(4)
        with cols[0]:
            st.metric("ğŸ§ Tá»•ng Ä‘á»‘i tÆ°á»£ng", stats['total'])
        with cols[1]: 
            st.metric("ğŸŸ¢ CÃ³ mÅ©", stats['helmet'], delta_color="off") 
        with cols[2]:
            st.metric("ğŸ”´ KhÃ´ng mÅ©", stats['no_helmet'], delta_color="off")
        with cols[3]:
            safety_rate = (stats['helmet'] / stats['total']) * 100 if stats['total'] > 0 else 0
            st.metric("ğŸ”’ Tá»· lá»‡ an toÃ n", f"{safety_rate:.1f}%")

        st.session_state.report_data.append({
            'Thá»i gian': datetime.now(),
            'Loáº¡i': 'áº¢nh',
            'Tá»•ng Ä‘á»‘i tÆ°á»£ng': stats['total'], 
            'CÃ³ mÅ©': stats['helmet'], 
            'KhÃ´ng mÅ©': stats['no_helmet'], 
            'Tá»· lá»‡ an toÃ n': f"{safety_rate:.1f}%"
        })

elif source == "ğŸ¥ Video":
    file = st.file_uploader("Táº£i video lÃªn", type=["mp4", "mov", "avi"], 
                             help="Chá»n video Ä‘á»ƒ phÃ¢n tÃ­ch theo thá»i gian thá»±c")
    if file:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
            tfile.write(file.read())
            path = tfile.name

        stats = process_video(path, confidence_threshold, iou_threshold)

        try: 
            os.remove(path)
        except: 
            pass

# Hiá»ƒn thá»‹ thá»‘ng kÃª tá»•ng quan
if st.session_state.report_data:
    st.markdown("---")
    st.subheader("ğŸ“Š Lá»‹ch sá»­ thá»‘ng kÃª")
    
    df = generate_report()
    st.dataframe(df, use_container_width=True)
    
    col1, col2 = st.columns([1, 3])
    with col1:
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "ğŸ’¾ Táº£i thá»‘ng kÃª",
            data=csv,
            file_name=f"helmet_detection_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime='text/csv'
        )
    
    with col2:
        if st.button("ğŸ—‘ï¸ XÃ³a toÃ n bá»™ lá»‹ch sá»­", type="primary"):
            st.session_state.report_data = []
            st.rerun()